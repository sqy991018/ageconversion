{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6794e5",
   "metadata": {},
   "source": [
    "# single "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from speechbrain.inference.vocoders import HIFIGAN\n",
    "from speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n",
    "\n",
    "# 加载预训练的 HiFi-GAN 声码器模型\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-libritts-16kHz\", savedir=\"pretrained_models/tts-hifigan-libritts-16kHz\")\n",
    "\n",
    "# 加载 CycleGAN 模型\n",
    "G_y2m = Generator()\n",
    "G_y2m.load_state_dict(torch.load('./best_G_m2y.pth', map_location=torch.device('cpu')))\n",
    "# G_y2m.load_state_dict(torch.load('best_G_o2m.pth', map_location=torch.device('cpu')))\n",
    "G_y2m.eval()\n",
    "\n",
    "\n",
    "def load_audio(file_path, target_sr=16000, duration=5):\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    \n",
    "    # 移除直流分量\n",
    "    audio = audio - audio.mean()\n",
    "\n",
    "    # 如果音频是立体声，转换为单声道\n",
    "    if audio.size(0) > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "    \n",
    "    # 计算目标长度\n",
    "    target_length = duration * target_sr\n",
    "    \n",
    "\n",
    "    if audio.size(1) > target_length:\n",
    "        audio = audio[:, :target_length]\n",
    "    elif audio.size(1) < target_length:\n",
    "        padding = target_length - audio.size(1)\n",
    "        repeat_times = (padding // audio.size(1)) + 1  \n",
    "        repeated_audio = audio.repeat(1, repeat_times)\n",
    "        audio = torch.cat((audio, repeated_audio[:, :padding]), dim=1)  \n",
    "    \n",
    "    return audio\n",
    "\n",
    "\n",
    "# 加载音频文件并生成 Mel 频谱图\n",
    "# signal = load_audio('./02_audio_16k/Batch1/Billy_Connoly/74/74_000459_000570_000.wav') \n",
    "signal = load_audio('./02_audio_16k/Batch2/Bob_Balaban/69/69_000758_002723_000.wav') \n",
    "signal = signal[0].squeeze()\n",
    "torchaudio.save('waveform.wav', signal.unsqueeze(0), 16000)\n",
    "signal = signal.squeeze()\n",
    "\n",
    "# 计算 Mel 频谱图\n",
    "spectrogram, _ = mel_spectogram(\n",
    "    audio=signal.squeeze(),\n",
    "    sample_rate=16000,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    n_mels=80,\n",
    "    n_fft=1024,\n",
    "    f_min=0.0,\n",
    "    f_max=8000.0,\n",
    "    power=1,\n",
    "    normalized=False,\n",
    "    min_max_energy_norm=True,\n",
    "    norm=\"slaney\",\n",
    "    mel_scale=\"slaney\",\n",
    "    compression=True\n",
    ")\n",
    "# 使用CycleGAN训练阶段的均值和标准差\n",
    "# mean = -4.9434876\n",
    "# std =   2.0440395\n",
    "mean = spectrogram.mean()\n",
    "std =  spectrogram.std()\n",
    "std_spectrogram = spectrogram\n",
    "std_spectrogram = (spectrogram - mean) / std\n",
    "std_spectrogram = std_spectrogram.unsqueeze(0)\n",
    "\n",
    "# 添加通道维度，使其形状为 (1, 80, T)\n",
    "with torch.no_grad():\n",
    "    generated_spectrogram = G_y2m(std_spectrogram).squeeze()\n",
    "\n",
    "# 反标准化生成的 Mel 频谱图\n",
    "generated_spectrogram = generated_spectrogram \n",
    "generated_spectrogram = generated_spectrogram * std + mean\n",
    "\n",
    "\n",
    "#  打印原始和生成的 Mel 频谱图\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Mel Spectrogram\")\n",
    "plt.imshow(spectrogram.squeeze().cpu().detach().numpy(), aspect='auto', origin='lower')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Generated Mel Spectrogram (Denormalized)\")\n",
    "plt.imshow(generated_spectrogram.cpu().detach().numpy(), aspect='auto', origin='lower')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#使用 HiFi-GAN 将 Mel 频谱图还原为音频\n",
    "with torch.no_grad():\n",
    "    original_waveform = hifi_gan.decode_batch(spectrogram)\n",
    "    generated_waveform = hifi_gan.decode_batch(generated_spectrogram.unsqueeze(0))\n",
    "# 放大生成的音频\n",
    "# amplification_factor = 30.0 \n",
    "# generated_waveform = generated_waveform * amplification_factor\n",
    "\n",
    "# 保存原始和生成的音频波形\n",
    "torchaudio.save('original_waveform.wav', original_waveform.squeeze(1), 16000)\n",
    "torchaudio.save('generated_waveform.wav', generated_waveform.squeeze(1), 16000)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b60d5b",
   "metadata": {},
   "source": [
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8605be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from speechbrain.inference.vocoders import HIFIGAN\n",
    "from speechbrain.lobes.models.FastSpeech2 import mel_spectogram\n",
    "import os\n",
    "\n",
    "\n",
    "# 加载预训练的 HiFi-GAN 声码器模型\n",
    "hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-libritts-16kHz\", savedir=\"pretrained_models/tts-hifigan-libritts-16kHz\")\n",
    "\n",
    "# 加载 CycleGAN 模型\n",
    "G_y2m = Generator()\n",
    "G_y2m.load_state_dict(torch.load('./best_G_y2m.pth', map_location=torch.device('cuda')))\n",
    "G_y2m.eval()\n",
    "\n",
    "G_o2m = Generator()\n",
    "G_o2m.load_state_dict(torch.load('./best_G_o2m.pth', map_location=torch.device('cuda')))\n",
    "G_o2m.eval()\n",
    "\n",
    "def load_audio(file_path, target_sr=16000):\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    \n",
    "    # 移除直流分量\n",
    "    audio = audio - audio.mean()\n",
    "\n",
    "    # 如果音频是立体声，转换为单声道\n",
    "    if audio.size(0) > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "    \n",
    "    # 处理音频长度为 3 秒\n",
    "    duration = 3  \n",
    "    target_length = duration * target_sr\n",
    "    \n",
    "\n",
    "    if audio.size(1) > target_length:\n",
    "        audio = audio[:, :target_length]\n",
    "    elif audio.size(1) < target_length:\n",
    "        padding = target_length - audio.size(1)\n",
    "        repeat_times = (padding // audio.size(1)) + 1  \n",
    "        repeated_audio = audio.repeat(1, repeat_times)  \n",
    "        audio = torch.cat((audio, repeated_audio[:, :padding]), dim=1)  \n",
    "    \n",
    "    return audio\n",
    "\n",
    "def process_and_save(file_path, age, target_dir):\n",
    "    signal = load_audio('02_audio_16k/' + file_path)\n",
    "\n",
    "    # 计算 Mel 频谱图\n",
    "    spectrogram, _ = mel_spectogram(\n",
    "        audio=signal.squeeze(),\n",
    "        sample_rate=16000,\n",
    "        hop_length=256,\n",
    "        win_length=1024,\n",
    "        n_mels=80,\n",
    "        n_fft=1024,\n",
    "        f_min=0.0,\n",
    "        f_max=8000.0,\n",
    "        power=1,\n",
    "        normalized=False,\n",
    "        min_max_energy_norm=True,\n",
    "        norm=\"slaney\",\n",
    "        mel_scale=\"slaney\",\n",
    "        compression=True\n",
    "    )\n",
    "    \n",
    "    # 使用CycleGAN训练阶段的均值和标准差\n",
    "    mean = -4.9434876\n",
    "    std = 2.0440395\n",
    "    std_spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    # 确保 std_spectrogram 是四维张量 (batch_size, channels, height, width)\n",
    "    std_spectrogram = std_spectrogram.unsqueeze(0)  # 添加 batch 和 channel 维度\n",
    "\n",
    "    if age < 35:\n",
    "        # 使用 CycleGAN G_y2m 处理\n",
    "        with torch.no_grad():\n",
    "            generated_spectrogram = G_y2m(std_spectrogram).squeeze()\n",
    "\n",
    "        # 反标准化生成的 Mel 频谱图\n",
    "        generated_spectrogram = generated_spectrogram * std + mean\n",
    "    \n",
    "    elif age > 55:\n",
    "        # 使用 CycleGAN G_o2m 处理\n",
    "        with torch.no_grad():\n",
    "            generated_spectrogram = G_o2m(std_spectrogram).squeeze()\n",
    "\n",
    "        # 反标准化生成的 Mel 频谱图\n",
    "        generated_spectrogram = generated_spectrogram * std + mean\n",
    "    \n",
    "    else:\n",
    "        generated_spectrogram = std_spectrogram.squeeze() * std + mean\n",
    "    \n",
    "    # 使用 HiFi-GAN 将 Mel 频谱图还原为音频\n",
    "    with torch.no_grad():\n",
    "        generated_waveform = hifi_gan.decode_batch(generated_spectrogram.unsqueeze(0))\n",
    "\n",
    "    save_path = os.path.join(target_dir, file_path)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    # 保存为 16-bit PCM 编码的 WAV 文件，确保 Kaldi 兼容\n",
    "    torchaudio.save(save_path, generated_waveform.squeeze(1), 16000, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('new_audio_samples.csv')\n",
    "\n",
    "# 获取所有音频文件路径及对应的年龄\n",
    "audio_files = df['fname'].tolist()\n",
    "ages = df['age'].tolist()\n",
    "\n",
    "# 处理并保存所有音频文件\n",
    "target_dir = './generated_audio'\n",
    "for file_path, age in tqdm(zip(audio_files, ages), total=len(audio_files)):\n",
    "    process_and_save(file_path, age, target_dir)\n",
    "\n",
    "print(\"all audios are saved in \", target_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
