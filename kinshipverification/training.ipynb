{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82068363",
   "metadata": {},
   "source": [
    "##  ivector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e99cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "# 解析 ivector.txt 文件\n",
    "def parse_ivector_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name_age = parts[0].split('/')\n",
    "            subject = name_age[0]\n",
    "            features = list(map(float, parts[1].strip('[]').split()))\n",
    "            data.append((subject, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Features'])\n",
    "\n",
    "# 读取 ivector 文件\n",
    "ivector_df = parse_ivector_file('../generated_ivector.txt')\n",
    "# ivector_df = parse_ivector_file('./ivector_feature/ivector.txt')\n",
    "# 读取 new_kin_relationship.csv\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到ivector_df\n",
    "ivector_df = ivector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(ivector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(ivector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "# 按subject分割数据集\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_subjects, test_size=0.1, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, ivector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.ivector_df = ivector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.ivector_df['Subject'], self.ivector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.ivector_df[self.ivector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "# 准备数据加载器\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, ivector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, ivector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, ivector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "# model and loss function \n",
    "# improved model\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)  \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0, lambda_reg=0.01): \n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "        reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "        loss = triplet_loss + self.lambda_reg * reg_term\n",
    "        return loss\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative = data[:3]  \n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            total_loss += loss.item()\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for anchor, positive, negative, _, _, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "        correct += (pos_dist < neg_dist).sum().item()\n",
    "        total += anchor.size(0)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "\n",
    "    val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "    test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "def evaluate_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            anchor, positive, negative = data[:3]  \n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "accuracy = evaluate_accuracy(model, test_loader)\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "relationship_accuracies = {\n",
    "    'BB': ['Brother', 'Brother'],\n",
    "    'SS': ['Sister', 'Sister'],\n",
    "    'BS': ['Brother', 'Sister'],\n",
    "    'FD': ['Father', 'Daughter'],\n",
    "    'FS': ['Father', 'Son'],\n",
    "    'MD': ['Mother', 'Daughter'],\n",
    "    'MS': ['Mother', 'Son']\n",
    "}\n",
    "for key, value in relationship_accuracies.items():\n",
    "    relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "    if not relationship_df.empty:\n",
    "        relationship_dataset = KinshipDataset(\n",
    "            scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "            scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "            relationship_df,\n",
    "            ivector_df,\n",
    "            scaler\n",
    "        )\n",
    "        relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "        relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "        relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "print(\"Accuracy by Relationship:\")\n",
    "for relationship, acc in relationship_accuracies.items():\n",
    "    print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "\n",
    "sample_idx = 0  \n",
    "anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "anchor_out = model(anchor.unsqueeze(0))\n",
    "positive_out = model(positive.unsqueeze(0))\n",
    "negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "\n",
    "pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "print(f\"Anchor Subject: {anchor_subject}\")\n",
    "print(f\"Positive Subject: {positive_subject}\")\n",
    "print(f\"Negative Subject: {negative_subject}\")\n",
    "print(f\"Positive distance: {pos_dist.item()}\")\n",
    "print(f\"Negative distance: {neg_dist.item()}\")\n",
    "print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\") \n",
    "\n",
    "# original model\n",
    "# class TripletNet(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(TripletNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.bn1 = nn.BatchNorm1d(256)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# class TripletLoss(nn.Module):\n",
    "#     def __init__(self, margin=1.0, lambda_reg=0.001):\n",
    "#         super(TripletLoss, self).__init__()\n",
    "#         self.margin = margin\n",
    "#         self.lambda_reg = lambda_reg\n",
    "\n",
    "#     def forward(self, anchor, positive, negative):\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "#         triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "#         reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "#         loss = triplet_loss + self.lambda_reg * reg_term\n",
    "#         return loss\n",
    "\n",
    "\n",
    "\n",
    "# model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "# criterion = TripletLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# # 训练模型\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for anchor, positive, negative, _, _, _ in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         anchor_out = model(anchor)\n",
    "#         positive_out = model(positive)\n",
    "#         negative_out = model(negative)\n",
    "#         loss = criterion(anchor_out, positive_out, negative_out)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#         correct += (pos_dist < neg_dist).sum().item()\n",
    "#         total += anchor.size(0)\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     train_accuracy = correct / total\n",
    "    \n",
    "\n",
    "#     val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "#     test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "#     print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "\n",
    "# test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# def evaluate_accuracy(model, test_loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loader:\n",
    "#             anchor, positive, negative = data[:3]  \n",
    "#             anchor_out = model(anchor)\n",
    "#             positive_out = model(positive)\n",
    "#             negative_out = model(negative)\n",
    "#             pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#             neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#             correct += (pos_dist < neg_dist).sum().item()\n",
    "#             total += anchor.size(0)\n",
    "#     accuracy = correct / total\n",
    "#     return accuracy\n",
    "# accuracy = evaluate_accuracy(model, test_loader)\n",
    "# print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "#\n",
    "# relationship_accuracies = {\n",
    "#     'BB': ['Brother', 'Brother'],\n",
    "#     'SS': ['Sister', 'Sister'],\n",
    "#     'BS': ['Brother', 'Sister'],\n",
    "#     'FD': ['Father', 'Daughter'],\n",
    "#     'FS': ['Father', 'Son'],\n",
    "#     'MD': ['Mother', 'Daughter'],\n",
    "#     'MS': ['Mother', 'Son']\n",
    "# }\n",
    "# for key, value in relationship_accuracies.items():\n",
    "#     relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "#     if not relationship_df.empty:\n",
    "#         relationship_dataset = KinshipDataset(\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "#             relationship_df,\n",
    "#             ivector_df,\n",
    "#             scaler\n",
    "#         )\n",
    "#         relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "#         relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "#         relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "# print(\"Accuracy by Relationship:\")\n",
    "# for relationship, acc in relationship_accuracies.items():\n",
    "#     print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "# sample_idx = 4000  \n",
    "# anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "# anchor_out = model(anchor.unsqueeze(0))\n",
    "# positive_out = model(positive.unsqueeze(0))\n",
    "# negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "# pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "# neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "# print(f\"Anchor Subject: {anchor_subject}\")\n",
    "# print(f\"Positive Subject: {positive_subject}\")\n",
    "# print(f\"Negative Subject: {negative_subject}\")\n",
    "# print(f\"Positive distance: {pos_dist.item()}\")\n",
    "# print(f\"Negative distance: {neg_dist.item()}\")\n",
    "# print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dbf9d",
   "metadata": {},
   "source": [
    "## xvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def parse_xvector_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name = parts[0].rsplit('-', 1)[0]  \n",
    "            features = parts[1].strip('[]').split()\n",
    "            features = np.array([float(x) for x in features])\n",
    "            data.append((name, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Features'])\n",
    "\n",
    "xvector_df = parse_xvector_file('../generated_xvector.txt')\n",
    "# xvector_df = parse_xvector_file('./xvector_feature/xvector.txt')\n",
    "# 读取 new_kin_relationship.csv 文件并清洗数据\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到xvector_df\n",
    "xvector_df = xvector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(xvector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(xvector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_subjects, test_size=0.1, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, xvector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.xvector_df = xvector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.xvector_df['Subject'], self.xvector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.xvector_df[self.xvector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, xvector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, xvector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, xvector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "\n",
    "# improved model\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)  \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0, lambda_reg=0.01):  \n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "        reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "        loss = triplet_loss + self.lambda_reg * reg_term\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative = data[:3]  \n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            total_loss += loss.item()\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for anchor, positive, negative, _, _, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "        correct += (pos_dist < neg_dist).sum().item()\n",
    "        total += anchor.size(0)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # 在验证集上进行评估\n",
    "    val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "    test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "def evaluate_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            anchor, positive, negative = data[:3]  # 只提取前三个元素\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "accuracy = evaluate_accuracy(model, test_loader)\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "# 按亲属关系计算准确率\n",
    "relationship_accuracies = {\n",
    "    'BB': ['Brother', 'Brother'],\n",
    "    'SS': ['Sister', 'Sister'],\n",
    "    'BS': ['Brother', 'Sister'],\n",
    "    'FD': ['Father', 'Daughter'],\n",
    "    'FS': ['Father', 'Son'],\n",
    "    'MD': ['Mother', 'Daughter'],\n",
    "    'MS': ['Mother', 'Son']\n",
    "}\n",
    "for key, value in relationship_accuracies.items():\n",
    "    relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "    if not relationship_df.empty:\n",
    "        relationship_dataset = KinshipDataset(\n",
    "            scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "            scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "            relationship_df,\n",
    "            xvector_df,\n",
    "            scaler\n",
    "        )\n",
    "        relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "        relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "        relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "print(\"Accuracy by Relationship:\")\n",
    "for relationship, acc in relationship_accuracies.items():\n",
    "    print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "# 选择一个三元组进行测试\n",
    "sample_idx = 0  # 可以更改为其他索引\n",
    "anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "anchor_out = model(anchor.unsqueeze(0))\n",
    "positive_out = model(positive.unsqueeze(0))\n",
    "negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "# 计算距离\n",
    "pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "print(f\"Anchor Subject: {anchor_subject}\")\n",
    "print(f\"Positive Subject: {positive_subject}\")\n",
    "print(f\"Negative Subject: {negative_subject}\")\n",
    "print(f\"Positive distance: {pos_dist.item()}\")\n",
    "print(f\"Negative distance: {neg_dist.item()}\")\n",
    "print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\") \n",
    "\n",
    "# original model\n",
    "# class TripletNet(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(TripletNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.bn1 = nn.BatchNorm1d(256)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# class TripletLoss(nn.Module):\n",
    "#     def __init__(self, margin=1.0, lambda_reg=0.001):\n",
    "#         super(TripletLoss, self).__init__()\n",
    "#         self.margin = margin\n",
    "#         self.lambda_reg = lambda_reg\n",
    "\n",
    "#     def forward(self, anchor, positive, negative):\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "#         triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "\n",
    "#         reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "#         loss = triplet_loss + self.lambda_reg * reg_term\n",
    "#         return loss\n",
    "\n",
    "\n",
    "\n",
    "# model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "# criterion = TripletLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for anchor, positive, negative, _, _, _ in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         anchor_out = model(anchor)\n",
    "#         positive_out = model(positive)\n",
    "#         negative_out = model(negative)\n",
    "#         loss = criterion(anchor_out, positive_out, negative_out)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#         correct += (pos_dist < neg_dist).sum().item()\n",
    "#         total += anchor.size(0)\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     train_accuracy = correct / total\n",
    "    \n",
    "#     # 在验证集上进行评估\n",
    "#     val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "#     test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "#     print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# # 测试模型\n",
    "# test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# def evaluate_accuracy(model, test_loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loader:\n",
    "#             anchor, positive, negative = data[:3] \n",
    "#             anchor_out = model(anchor)\n",
    "#             positive_out = model(positive)\n",
    "#             negative_out = model(negative)\n",
    "#             pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#             neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#             correct += (pos_dist < neg_dist).sum().item()\n",
    "#             total += anchor.size(0)\n",
    "#     accuracy = correct / total\n",
    "#     return accuracy\n",
    "# accuracy = evaluate_accuracy(model, test_loader)\n",
    "# print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# relationship_accuracies = {\n",
    "#     'BB': ['Brother', 'Brother'],\n",
    "#     'SS': ['Sister', 'Sister'],\n",
    "#     'BS': ['Brother', 'Sister'],\n",
    "#     'FD': ['Father', 'Daughter'],\n",
    "#     'FS': ['Father', 'Son'],\n",
    "#     'MD': ['Mother', 'Daughter'],\n",
    "#     'MS': ['Mother', 'Son']\n",
    "# }\n",
    "# for key, value in relationship_accuracies.items():\n",
    "#     relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "#     if not relationship_df.empty:\n",
    "#         relationship_dataset = KinshipDataset(\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "#             relationship_df,\n",
    "#             xvector_df,\n",
    "#             scaler\n",
    "#         )\n",
    "#         relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "#         relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "#         relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "# print(\"Accuracy by Relationship:\")\n",
    "# for relationship, acc in relationship_accuracies.items():\n",
    "#     print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "\n",
    "# sample_idx = 4000  \n",
    "# anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "# anchor_out = model(anchor.unsqueeze(0))\n",
    "# positive_out = model(positive.unsqueeze(0))\n",
    "# negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "\n",
    "# pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "# neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "# print(f\"Anchor Subject: {anchor_subject}\")\n",
    "# print(f\"Positive Subject: {positive_subject}\")\n",
    "# print(f\"Negative Subject: {negative_subject}\")\n",
    "# print(f\"Positive distance: {pos_dist.item()}\")\n",
    "# print(f\"Negative distance: {neg_dist.item()}\")\n",
    "# print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8985874",
   "metadata": {},
   "source": [
    "### wav2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 解析 resvector.txt 文件\n",
    "def parse_resvector_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name_age = parts[0].split('/')\n",
    "#             print(name_age)\n",
    "            subject = name_age[2]\n",
    "            age = int(name_age[3])\n",
    "            features_str = parts[1].strip('[]').rstrip(',')\n",
    "            features = list(map(float, features_str.split(', ')))\n",
    "            data.append((subject, age, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Age', 'Features'])\n",
    "\n",
    "# 读取 ivector 文件\n",
    "xvector_df = parse_resvector_file('../generated_wav2vec_pretrained.txt')\n",
    "# xvector_df = parse_resvector_file('./generated_wav2vec_pretrained.txt')\n",
    "\n",
    "# 读取 new_kin_relationship.csv 文件并清洗数据\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到xvector_df\n",
    "xvector_df = xvector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(xvector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(xvector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 按subject分割数据集\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_subjects, test_size=0.1, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, xvector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.xvector_df = xvector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.xvector_df['Subject'], self.xvector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.xvector_df[self.xvector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "# 准备数据加载器\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, xvector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, xvector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, xvector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n",
    "\n",
    "# improved model\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)  \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0, lambda_reg=0.01):  \n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "        # 正则化项\n",
    "        reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "        loss = triplet_loss + self.lambda_reg * reg_term\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative = data[:3] \n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            total_loss += loss.item()\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for anchor, positive, negative, _, _, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "        correct += (pos_dist < neg_dist).sum().item()\n",
    "        total += anchor.size(0)\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    # 在验证集上进行评估\n",
    "    val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "    test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "def evaluate_accuracy(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            anchor, positive, negative = data[:3]  # 只提取前三个元素\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            correct += (pos_dist < neg_dist).sum().item()\n",
    "            total += anchor.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "accuracy = evaluate_accuracy(model, test_loader)\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "# 按亲属关系计算准确率\n",
    "relationship_accuracies = {\n",
    "    'BB': ['Brother', 'Brother'],\n",
    "    'SS': ['Sister', 'Sister'],\n",
    "    'BS': ['Brother', 'Sister'],\n",
    "    'FD': ['Father', 'Daughter'],\n",
    "    'FS': ['Father', 'Son'],\n",
    "    'MD': ['Mother', 'Daughter'],\n",
    "    'MS': ['Mother', 'Son']\n",
    "}\n",
    "for key, value in relationship_accuracies.items():\n",
    "    relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "    if not relationship_df.empty:\n",
    "        relationship_dataset = KinshipDataset(\n",
    "            scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "            scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "            relationship_df,\n",
    "            xvector_df,\n",
    "            scaler\n",
    "        )\n",
    "        relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "        relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "        relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "print(\"Accuracy by Relationship:\")\n",
    "for relationship, acc in relationship_accuracies.items():\n",
    "    print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "# 选择一个三元组进行测试\n",
    "sample_idx = 0  # 可以更改为其他索引\n",
    "anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "anchor_out = model(anchor.unsqueeze(0))\n",
    "positive_out = model(positive.unsqueeze(0))\n",
    "negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "# 计算距离\n",
    "pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "print(f\"Anchor Subject: {anchor_subject}\")\n",
    "print(f\"Positive Subject: {positive_subject}\")\n",
    "print(f\"Negative Subject: {negative_subject}\")\n",
    "print(f\"Positive distance: {pos_dist.item()}\")\n",
    "print(f\"Negative distance: {neg_dist.item()}\")\n",
    "print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\")  # 如果正样本距离小于负样本距离，则预测正确\n",
    "\n",
    "# orginal model\n",
    "# class TripletNet(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(TripletNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.bn1 = nn.BatchNorm1d(256)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# class TripletLoss(nn.Module):\n",
    "#     def __init__(self, margin=1.0, lambda_reg=0.001):\n",
    "#         super(TripletLoss, self).__init__()\n",
    "#         self.margin = margin\n",
    "#         self.lambda_reg = lambda_reg\n",
    "\n",
    "#     def forward(self, anchor, positive, negative):\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "#         triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "\n",
    "#         reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "#         loss = triplet_loss + self.lambda_reg * reg_term\n",
    "#         return loss\n",
    "\n",
    "# def evaluate_model(model, criterion, data_loader):\n",
    "#     model.eval()\n",
    "#     total_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in data_loader:\n",
    "#             anchor, positive, negative = data[:3]  \n",
    "#             anchor_out = model(anchor)\n",
    "#             positive_out = model(positive)\n",
    "#             negative_out = model(negative)\n",
    "#             loss = criterion(anchor_out, positive_out, negative_out)\n",
    "#             total_loss += loss.item()\n",
    "#             pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#             neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#             correct += (pos_dist < neg_dist).sum().item()\n",
    "#             total += anchor.size(0)\n",
    "#     avg_loss = total_loss / len(data_loader)\n",
    "#     accuracy = correct / total\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "# criterion = TripletLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for anchor, positive, negative, _, _, _ in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         anchor_out = model(anchor)\n",
    "#         positive_out = model(positive)\n",
    "#         negative_out = model(negative)\n",
    "#         loss = criterion(anchor_out, positive_out, negative_out)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item()\n",
    "#         pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#         neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#         correct += (pos_dist < neg_dist).sum().item()\n",
    "#         total += anchor.size(0)\n",
    "    \n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "#     train_accuracy = correct / total\n",
    "    \n",
    "#     # 在验证集上进行评估\n",
    "#     val_loss, val_accuracy = evaluate_model(model, criterion, val_loader)\n",
    "#     test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "    \n",
    "#     print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "#     print(f'Epoch {epoch+1}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# # 测试模型\n",
    "# test_loss, test_accuracy = evaluate_model(model, criterion, test_loader)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Overall Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# def evaluate_accuracy(model, test_loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in test_loader:\n",
    "#             anchor, positive, negative = data[:3]\n",
    "#             anchor_out = model(anchor)\n",
    "#             positive_out = model(positive)\n",
    "#             negative_out = model(negative)\n",
    "#             pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "#             neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "#             correct += (pos_dist < neg_dist).sum().item()\n",
    "#             total += anchor.size(0)\n",
    "#     accuracy = correct / total\n",
    "#     return accuracy\n",
    "# accuracy = evaluate_accuracy(model, test_loader)\n",
    "# print(f'Overall Accuracy: {accuracy * 100:.2f}%')\n",
    "# # 按亲属关系计算准确率\n",
    "# relationship_accuracies = {\n",
    "#     'BB': ['Brother', 'Brother'],\n",
    "#     'SS': ['Sister', 'Sister'],\n",
    "#     'BS': ['Brother', 'Sister'],\n",
    "#     'FD': ['Father', 'Daughter'],\n",
    "#     'FS': ['Father', 'Son'],\n",
    "#     'MD': ['Mother', 'Daughter'],\n",
    "#     'MS': ['Mother', 'Son']\n",
    "# }\n",
    "# for key, value in relationship_accuracies.items():\n",
    "#     relationship_df = test[(test['Relationship1'] == value[0]) & (test['Relationship2'] == value[1])]\n",
    "#     if not relationship_df.empty:\n",
    "#         relationship_dataset = KinshipDataset(\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_1'])),\n",
    "#             scaler.transform(np.vstack(relationship_df['Features_2'])),\n",
    "#             relationship_df,\n",
    "#             xvector_df,\n",
    "#             scaler\n",
    "#         )\n",
    "#         relationship_loader = DataLoader(relationship_dataset, batch_size=32, shuffle=True)\n",
    "#         relationship_accuracy = evaluate_accuracy(model, relationship_loader)\n",
    "#         relationship_accuracies[key] = relationship_accuracy * 100\n",
    "\n",
    "# print(\"Accuracy by Relationship:\")\n",
    "# for relationship, acc in relationship_accuracies.items():\n",
    "#     print(f\"{relationship}: {acc:.2f}%\")\n",
    "\n",
    "# # 选择一个三元组进行测试\n",
    "# sample_idx = 4000 \n",
    "# anchor, positive, negative, anchor_subject, positive_subject, negative_subject = test_dataset[sample_idx]\n",
    "# anchor_out = model(anchor.unsqueeze(0))\n",
    "# positive_out = model(positive.unsqueeze(0))\n",
    "# negative_out = model(negative.unsqueeze(0))\n",
    "\n",
    "\n",
    "# pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "# neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "# print(f\"Anchor Subject: {anchor_subject}\")\n",
    "# print(f\"Positive Subject: {positive_subject}\")\n",
    "# print(f\"Negative Subject: {negative_subject}\")\n",
    "# print(f\"Positive distance: {pos_dist.item()}\")\n",
    "# print(f\"Negative distance: {neg_dist.item()}\")\n",
    "# print(f\"Correct prediction: {pos_dist.item() < neg_dist.item()}\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
