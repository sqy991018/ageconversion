{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82068363",
   "metadata": {},
   "source": [
    "##  ivector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import optuna\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "# 解析 ivector.txt 文件\n",
    "def parse_ivector_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name_age = parts[0].split('/')\n",
    "            subject = name_age[0]\n",
    "            features = list(map(float, parts[1].strip('[]').split()))\n",
    "            data.append((subject, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Features'])\n",
    "\n",
    "# 读取 ivector 文件\n",
    "ivector_df = parse_ivector_file('../generated_ivector.txt')\n",
    "# ivector_df = parse_ivector_file('./ivector_feature/ivector.txt')\n",
    "# 读取 new_kin_relationship.csv 文件并清洗数据\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到ivector_df\n",
    "ivector_df = ivector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(ivector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(ivector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "# 按subject分割数据集\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_val_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_val_subjects, test_size=0.125, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, ivector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.ivector_df = ivector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.ivector_df['Subject'], self.ivector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.ivector_df[self.ivector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "# 准备数据加载器\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, ivector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, ivector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, ivector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dbf9d",
   "metadata": {},
   "source": [
    "## xvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 读取 xvector.txt 文件并解析数据\n",
    "def parse_xvector_file(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name = parts[0].rsplit('-', 1)[0]  # 确保格式一致\n",
    "            features = parts[1].strip('[]').split()\n",
    "            features = np.array([float(x) for x in features])\n",
    "            data.append((name, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Features'])\n",
    "\n",
    "xvector_df = parse_xvector_file('../generated_xvector.txt')\n",
    "# xvector_df = parse_xvector_file('./xvector_feature/xvector.txt')\n",
    "# 读取 new_kin_relationship.csv 文件并清洗数据\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到xvector_df\n",
    "xvector_df = xvector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(xvector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(xvector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "# 按subject分割数据集\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_val_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_val_subjects, test_size=0.125, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, xvector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.xvector_df = xvector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.xvector_df['Subject'], self.xvector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.xvector_df[self.xvector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "# 准备数据加载器\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, xvector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, xvector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, xvector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8985874",
   "metadata": {},
   "source": [
    "## wav2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1019d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject1     Subject2 Relationship1 Relationship2  Subject_1  Age_1  \\\n",
      "0  Tom_Hanks  Colin_Hanks        Father           Son  Tom_Hanks     28   \n",
      "1  Tom_Hanks  Colin_Hanks        Father           Son  Tom_Hanks     28   \n",
      "2  Tom_Hanks  Colin_Hanks        Father           Son  Tom_Hanks     28   \n",
      "3  Tom_Hanks  Colin_Hanks        Father           Son  Tom_Hanks     28   \n",
      "4  Tom_Hanks  Colin_Hanks        Father           Son  Tom_Hanks     28   \n",
      "\n",
      "                                          Features_1 Gender_1    Subject_2  \\\n",
      "0  [0.008313, 0.003505, -0.011092, -0.005062, -0....     Male  Colin_Hanks   \n",
      "1  [0.008313, 0.003505, -0.011092, -0.005062, -0....     Male  Colin_Hanks   \n",
      "2  [0.008313, 0.003505, -0.011092, -0.005062, -0....     Male  Colin_Hanks   \n",
      "3  [0.008313, 0.003505, -0.011092, -0.005062, -0....     Male  Colin_Hanks   \n",
      "4  [0.008313, 0.003505, -0.011092, -0.005062, -0....     Male  Colin_Hanks   \n",
      "\n",
      "   Age_2                                         Features_2 Gender_2  \n",
      "0     25  [0.008037, 0.003348, -0.010465, -0.006155, -0....     Male  \n",
      "1     25  [0.008195, 0.003465, -0.012194, -0.006923, -0....     Male  \n",
      "2     25  [0.0067, 0.002788, -0.011537, -0.007553, -0.01...     Male  \n",
      "3     28  [0.007132, 0.002802, -0.010947, -0.006406, -0....     Male  \n",
      "4     31  [0.021638, 0.004289, 0.042743, -0.028012, 0.00...     Male  \n",
      "不同长度的特征数组数目：\n",
      "Features_1\n",
      "1024    288040\n",
      "Name: count, dtype: int64\n",
      "261 38 75\n",
      "183817 44292 59931\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 解析 resvector.txt 文件\n",
    "def parse_resvector_file0(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name_age = parts[0].split('/')\n",
    "#             print(name_age)\n",
    "            subject = name_age[0]\n",
    "            age = int(name_age[1])\n",
    "            features_str = parts[1].strip('[]').rstrip(',')\n",
    "            features = list(map(float, features_str.split(', ')))\n",
    "            data.append((subject, age, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Age', 'Features'])\n",
    "# 解析 resvector.txt 文件\n",
    "def parse_resvector_file1(filepath):\n",
    "    data = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            name_age = parts[0].split('/')\n",
    "#             print(name_age)\n",
    "            subject = name_age[0]\n",
    "            age = int(name_age[1])\n",
    "            features_str = parts[1].strip('[]').rstrip(',')\n",
    "            features = list(map(float, features_str.split(', ')))\n",
    "            data.append((subject, age, features))\n",
    "    return pd.DataFrame(data, columns=['Subject', 'Age', 'Features'])\n",
    "# 读取 ivector 文件\n",
    "xvector_df = parse_resvector_file0('./generated_wav2vec_pretrained.txt')\n",
    "# xvector_df = parse_resvector_file1('./wav2vec_pretrained.txt')\n",
    "\n",
    "# 读取 new_kin_relationship.csv 文件并清洗数据\n",
    "new_kin_relationships_file = pd.read_csv('./new_kin_relationships.csv')\n",
    "new_kin_relationships_file.columns = ['Subject1', 'Subject2', 'Relationship1', 'Relationship2']\n",
    "new_kin_relationships_file['Subject1'] = new_kin_relationships_file['Subject1'].str.strip()\n",
    "new_kin_relationships_file['Subject2'] = new_kin_relationships_file['Subject2'].str.strip()\n",
    "\n",
    "# 读取 genders.csv 文件并合并性别信息\n",
    "genders_df = pd.read_csv('./new_genders.csv')\n",
    "genders_df.columns = ['Subject', 'Gender']\n",
    "genders_df['Subject'] = genders_df['Subject'].str.strip()\n",
    "\n",
    "# 合并性别信息到xvector_df\n",
    "xvector_df = xvector_df.merge(genders_df, on='Subject', how='inner')\n",
    "\n",
    "# 合并数据\n",
    "merged_df1 = new_kin_relationships_file.merge(xvector_df, left_on='Subject1', right_on='Subject', how='inner')\n",
    "merged_df = merged_df1.merge(xvector_df, left_on='Subject2', right_on='Subject', how='inner', suffixes=('_1', '_2'))\n",
    "\n",
    "# 打印合并后的数据\n",
    "print(merged_df.head())\n",
    "feature_lengths = merged_df['Features_1'].apply(len)\n",
    "print(\"不同长度的特征数组数目：\")\n",
    "print(feature_lengths.value_counts())\n",
    "\n",
    "# 按subject分割数据集\n",
    "subjects = merged_df['Subject_1'].unique()\n",
    "train_val_subjects, test_subjects = train_test_split(subjects, test_size=0.2, random_state=42)\n",
    "train_subjects, val_subjects = train_test_split(train_val_subjects, test_size=0.125, random_state=42)\n",
    "print(len(train_subjects),len(val_subjects),len(test_subjects))\n",
    "train = merged_df[merged_df['Subject_1'].isin(train_subjects)]\n",
    "val = merged_df[merged_df['Subject_1'].isin(val_subjects)]\n",
    "test = merged_df[merged_df['Subject_1'].isin(test_subjects)]\n",
    "\n",
    "\n",
    "# 标准化特征\n",
    "scaler = StandardScaler()\n",
    "train_features_1 = scaler.fit_transform(np.vstack(train['Features_1']))\n",
    "train_features_2 = scaler.fit_transform(np.vstack(train['Features_2']))\n",
    "val_features_1 = scaler.transform(np.vstack(val['Features_1']))\n",
    "val_features_2 = scaler.transform(np.vstack(val['Features_2']))\n",
    "test_features_1 = scaler.transform(np.vstack(test['Features_1']))\n",
    "test_features_2 = scaler.transform(np.vstack(test['Features_2']))\n",
    "\n",
    "class KinshipDataset(Dataset):\n",
    "    def __init__(self, anchor_features, positive_features, relationships, xvector_df, scaler):\n",
    "        self.anchor_features = anchor_features\n",
    "        self.positive_features = positive_features\n",
    "        self.relationships = relationships\n",
    "        self.xvector_df = xvector_df\n",
    "        self.scaler = scaler\n",
    "        self.subjects = list(set(self.relationships['Subject1']).union(set(self.relationships['Subject2'])))\n",
    "        self.subject_gender = dict(zip(self.xvector_df['Subject'], self.xvector_df['Gender']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anchor_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor = self.anchor_features[idx]\n",
    "        positive = self.positive_features[idx]\n",
    "        anchor_subject = self.relationships.iloc[idx]['Subject1']\n",
    "        positive_subject = self.relationships.iloc[idx]['Subject2']\n",
    "        positive_gender = self.subject_gender[positive_subject]\n",
    "\n",
    "        # 随机选择一个负样本，确保性别相同\n",
    "        while True:\n",
    "            negative_subject = np.random.choice(self.subjects)\n",
    "            if (negative_subject != anchor_subject and \n",
    "                negative_subject != positive_subject and \n",
    "                self.subject_gender[negative_subject] == positive_gender):\n",
    "                break\n",
    "        \n",
    "        negative_features = self.xvector_df[self.xvector_df['Subject'] == negative_subject]['Features'].values[0]\n",
    "        negative = self.scaler.transform([negative_features])[0]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(anchor, dtype=torch.float32), \n",
    "            torch.tensor(positive, dtype=torch.float32), \n",
    "            torch.tensor(negative, dtype=torch.float32),\n",
    "            anchor_subject,\n",
    "            positive_subject,\n",
    "            negative_subject\n",
    "        )\n",
    "\n",
    "# 准备数据加载器\n",
    "train_dataset = KinshipDataset(train_features_1, train_features_2, train, xvector_df, scaler)\n",
    "val_dataset = KinshipDataset(val_features_1, val_features_2, val, xvector_df, scaler)\n",
    "test_dataset = KinshipDataset(test_features_1, test_features_2, test, xvector_df, scaler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(len(train_dataset),len(val_dataset),len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470d06ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0819, Validation Loss: 0.0372\n",
      "Best Threshold: 1.080179699168487, Best Accuracy: 71.49%\n",
      "Test Accuracy with threshold 1.080179699168487: 68.39%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# old model\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256,  bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 128,  bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "#  new model   \n",
    "# class TripletNet(nn.Module):\n",
    "#     def __init__(self, input_dim):\n",
    "#         super(TripletNet, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 256)\n",
    "#         self.bn1 = nn.BatchNorm1d(256)\n",
    "#         self.dropout = nn.Dropout(0.5)  # 添加Dropout层\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.dropout(x)  # 应用Dropout\n",
    "#         x = self.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "    \n",
    "# 定义三元组损失函数，调整正则化项的系数 lambda=1e-3\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1, lambda_reg=1e-3):  # 增加正则化系数\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.lambda_reg = lambda_reg\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = torch.nn.functional.pairwise_distance(anchor, positive)\n",
    "        neg_dist = torch.nn.functional.pairwise_distance(anchor, negative)\n",
    "        triplet_loss = torch.relu(pos_dist - neg_dist + self.margin).mean()\n",
    "\n",
    "        # 正则化项\n",
    "        reg_term = (anchor.norm(2) + positive.norm(2) + negative.norm(2)).mean()\n",
    "        loss = triplet_loss + self.lambda_reg * reg_term\n",
    "        return loss\n",
    "\n",
    "# 定义训练函数\n",
    "def train_epoch(model, criterion, optimizer, data_loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for anchor, positive, negative, _, _, _ in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        anchor_out = model(anchor)\n",
    "        positive_out = model(positive)\n",
    "        negative_out = model(negative)\n",
    "        loss = criterion(anchor_out, positive_out, negative_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss\n",
    "\n",
    "# 定义验证和测试时使用的函数来计算最佳阈值\n",
    "def evaluate_best_threshold_by_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    all_distances = []\n",
    "    all_labels = []\n",
    "\n",
    "    # 计算所有anchor-positive和anchor-negative样本之间的距离，并收集真实标签\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative = data[:3]\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "            \n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "            \n",
    "            all_distances.extend(pos_dist.cpu().numpy())  # 正样本对距离\n",
    "            all_labels.extend([1] * len(pos_dist))  # 正样本对标签\n",
    "            \n",
    "            all_distances.extend(neg_dist.cpu().numpy())  # 负样本对距离\n",
    "            all_labels.extend([0] * len(neg_dist))  # 负样本对标签\n",
    "\n",
    "    # 将正负样本对距离结合在一起，并获取最小和最大距离\n",
    "    all_distances = np.array(all_distances)\n",
    "    all_labels = np.array(all_labels)\n",
    "    min_distance = np.min(all_distances)\n",
    "    max_distance = np.max(all_distances)\n",
    "\n",
    "    # 设置阈值范围，通常设置为从最小距离到最大距离的范围\n",
    "    thresholds = np.linspace(min_distance, max_distance, 100)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_threshold =0\n",
    "\n",
    "    # 遍历所有阈值，计算在该阈值下的准确率\n",
    "    for threshold in thresholds:\n",
    "        # 对于正样本，距离小于阈值的应该分类为正样本 (1)\n",
    "        # 对于负样本，距离大于阈值的应该分类为负样本 (0)\n",
    "        predictions = (all_distances < threshold).astype(int)\n",
    "        accuracy = np.mean(predictions == all_labels)\n",
    "\n",
    "        # 找到准确率最高的阈值\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"Best Threshold: {best_threshold}, Best Accuracy: {best_accuracy * 100:.2f}%\")\n",
    "    return best_threshold\n",
    "\n",
    "# 定义测试阶段使用的函数\n",
    "def evaluate_with_threshold(model, data_loader, threshold):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative = data[:3]\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "            # 正样本 (anchor-positive) 距离小于阈值则为正确\n",
    "            correct += (pos_dist < threshold).sum().item()\n",
    "            # 负样本 (anchor-negative) 距离大于阈值则为正确\n",
    "            correct += (neg_dist >= threshold).sum().item()\n",
    "            total += 2 * anchor.size(0)  # 每个batch里有2倍的样本（正负样本对）\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy with threshold {threshold}: {accuracy * 100:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = TripletNet(input_dim=train_features_1.shape[1])\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "\n",
    "# 训练\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, criterion, optimizer, train_loader)\n",
    "    val_loss = train_epoch(model, criterion, optimizer, test_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "\n",
    "best_threshold = evaluate_best_threshold_by_accuracy(model, test_loader)\n",
    "\n",
    "# 在测试集上使用最佳阈值进行评估\n",
    "test_accuracy = evaluate_with_threshold(model, val_loader, best_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80277e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_threshold_by_relationship(model, data_loader, threshold):\n",
    "    model.eval()\n",
    "\n",
    "    # 初始化每种亲属关系的计数和准确率\n",
    "    relationship_accuracies = {\n",
    "        'BB': ['Brother', 'Brother'],\n",
    "        'SS': ['Sister', 'Sister'],\n",
    "        'BS': ['Brother', 'Sister'],\n",
    "        'FD': ['Father', 'Daughter'],\n",
    "        'FS': ['Father', 'Son'],\n",
    "        'MD': ['Mother', 'Daughter'],\n",
    "        'MS': ['Mother', 'Son']\n",
    "    }\n",
    "\n",
    "    # 用于存储每种亲属关系的统计信息\n",
    "    relationship_stats = {key: {'correct_pos': 0, 'correct_neg': 0, 'total': 0} for key in relationship_accuracies.keys()}\n",
    "\n",
    "    correct_pos_total = 0\n",
    "    correct_neg_total = 0\n",
    "    total_pos_neg = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            anchor, positive, negative, anchor_subject, positive_subject, negative_subject = data\n",
    "\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "\n",
    "            # 计算正对和负对的距离\n",
    "            pos_dist = torch.nn.functional.pairwise_distance(anchor_out, positive_out)\n",
    "            neg_dist = torch.nn.functional.pairwise_distance(anchor_out, negative_out)\n",
    "\n",
    "            # 遍历每个三元组，找到对应的亲属关系\n",
    "            for idx in range(len(anchor_subject)):\n",
    "                # 查找每对 anchor 和 positive 的亲属关系\n",
    "                relationship_df = merged_df[\n",
    "                    (merged_df['Subject1'] == anchor_subject[idx]) &\n",
    "                    (merged_df['Subject2'] == positive_subject[idx])\n",
    "                ]\n",
    "                \n",
    "                if not relationship_df.empty:\n",
    "                    relationship1 = relationship_df.iloc[0]['Relationship1']\n",
    "                    relationship2 = relationship_df.iloc[0]['Relationship2']\n",
    "                    \n",
    "                    # 通过亲属关系映射找到对应的关系类别\n",
    "                    for key, value in relationship_accuracies.items():\n",
    "                        if relationship1 == value[0] and relationship2 == value[1]:\n",
    "                            relationship_stats[key]['total'] += 1  # 正对和负对的总样本数量相同\n",
    "\n",
    "                            # 统计正对的预测情况\n",
    "                            if pos_dist[idx] < threshold:\n",
    "                                relationship_stats[key]['correct_pos'] += 1\n",
    "                                correct_pos_total += 1  # 全局正对统计\n",
    "                            \n",
    "                            # 统计负对的预测情况\n",
    "                            if neg_dist[idx] >= threshold:\n",
    "                                relationship_stats[key]['correct_neg'] += 1\n",
    "                                correct_neg_total += 1  # 全局负对统计\n",
    "\n",
    "                            total_pos_neg += 1  # 记录正对和负对样本的总数\n",
    "\n",
    "    # 计算整体准确率\n",
    "    overall_accuracy = (correct_pos_total + correct_neg_total) / (2 * total_pos_neg)\n",
    "    print(f\"Overall Test Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # 打印每种亲属关系的统计信息\n",
    "    for relationship, stats in relationship_stats.items():\n",
    "        if stats['total'] > 0:\n",
    "            pos_accuracy = stats['correct_pos'] / stats['total']\n",
    "            neg_accuracy = stats['correct_neg'] / stats['total']\n",
    "            overall_relationship_accuracy = (stats['correct_pos'] + stats['correct_neg']) / (2 * stats['total'])\n",
    "            print(f\"共有 {stats['total']} 条 {relationship} 样本正对, {stats['total']} 条 {relationship} 样本负对\")\n",
    "            print(f\"{relationship} 样本正对预测正确 {stats['correct_pos']} 条，负对预测正确 {stats['correct_neg']} 条\")\n",
    "            print(f\"{relationship} 的总准确率为: {overall_relationship_accuracy * 100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{relationship}: 0 条样本\")\n",
    "\n",
    "    return overall_accuracy\n",
    "\n",
    "\n",
    "# 使用最佳阈值并统计每种亲属关系和整体的预测情况\n",
    "test_accuracy = evaluate_with_threshold_by_relationship(model, val_loader, best_threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
